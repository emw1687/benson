{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load pickled file into dataframe\n",
    "def open_pickle(pkl_file):\n",
    "    with open(pkl_file, 'rb') as picklefile:\n",
    "        return pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data collected from wikipedia and goodreads\n",
    "nyt = open_pickle('../data/interim/nyt_cleaned.pkl')\n",
    "books = open_pickle('../data/raw/books_scraped.pkl')\n",
    "authors = open_pickle('../data/raw/authors_scraped.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert number strings to numeric values\n",
    "def to_num(df):\n",
    "    return df.apply(lambda x: pd.to_numeric(x, errors='ignore'))\n",
    "\n",
    "nyt = to_num(nyt)\n",
    "books = to_num(books)\n",
    "authors = to_num(authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean author data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add author ids to authors df\n",
    "a_ids = books[['a_id', 'author']].drop_duplicates()\n",
    "authors = authors.merge(a_ids, on='a_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_id                    0.000000\n",
      "a_fans_count            0.000000\n",
      "a_works_count           0.000000\n",
      "gender                  0.141079\n",
      "hometown                0.136929\n",
      "birth_date              0.319502\n",
      "death_date              0.543568\n",
      "a_avg_rating            0.000000\n",
      "a_ratings_count         0.000000\n",
      "a_text_reviews_count    0.000000\n",
      "author                  0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#drop birth_date, death_date because of number of NANs\n",
    "print authors.isnull().sum()/len(authors)\n",
    "labels = ['birth_date', 'death_date']\n",
    "authors.drop(labels=labels, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fill gender and hometown NANs with 'not reported'\n",
    "authors['gender'].fillna('not reported', inplace=True)\n",
    "authors['hometown'].fillna('not reported', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate number of weeks each book was on NYT lists by book, and by author\n",
    "nyt_by_book = nyt.groupby(by=['title', 'author'], as_index=False).count()[['title', 'author', 'date']]\n",
    "nyt_by_author = nyt.groupby(by='author', as_index=False).count()[['author', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rename columns to be able to join nyt df with goodreads dfs\n",
    "columns = {'title': 'nyt_title',\n",
    "           'date': 'b_wks_on_list'}\n",
    "\n",
    "nyt_by_book.rename(columns=columns, inplace=True)\n",
    "nyt_by_author.rename(columns={'date': 'a_wks_on_list'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate number of books on nyt for each author\n",
    "nyt_books_by_author = nyt.groupby(['author','title'], as_index=False).count()[['author','title']]\n",
    "nyt_books_by_author = nyt_books_by_author.groupby('author', as_index=False).count()\n",
    "nyt_books_by_author.rename(columns={'title': 'a_books_on_list'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add number of weeks each author has been on NYT list\n",
    "nyt_by_author['author'] = nyt_by_author['author'].apply(lambda x: x.decode('utf-8'))\n",
    "authors = authors.merge(nyt_by_author, on='author', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add number of weeks each author has on NYT list\n",
    "nyt_books_by_author['author'] = nyt_books_by_author['author'].apply(lambda x: x.decode('utf-8'))\n",
    "authors = authors.merge(nyt_books_by_author, on='author', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authors.loc[authors['author'].str.contains('Betty'), 'a_wks_on_list'] = 22\n",
    "authors.loc[authors['author'].str.contains('Betty'), 'a_books_on_list'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean books data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#determine which decade each book was on the NYT list\n",
    "#if in more than one decade, only keep first decade (about 6 books)\n",
    "books_by_decade = nyt.groupby(['title', 'decade'], as_index=False).count()[['title', 'decade']]\n",
    "books_by_decade.drop_duplicates(subset='title', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add number of weeks each book was on NYT list\n",
    "books = books.merge(nyt_by_book, on='nyt_title', how='left')\n",
    "\n",
    "#add author data to each book\n",
    "books = books.merge(authors, on='a_id')\n",
    "\n",
    "#add which decade a book was in for each book\n",
    "books_by_decade.rename(columns={'title': 'nyt_title'}, inplace=True)\n",
    "books = books.merge(books_by_decade, on='nyt_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop author names from books df\n",
    "books = books.drop(['author_x', 'author_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fix typo in pub_yr\n",
    "books.loc[books['pub_yr']==214,'pub_yr'] = 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_id                    0.000000\n",
      "gr_title                0.000000\n",
      "nyt_title               0.000000\n",
      "b_count                 0.000000\n",
      "pub_day                 0.407008\n",
      "pub_mon                 0.369272\n",
      "pub_yr                  0.000000\n",
      "b_avg_rating            0.000000\n",
      "b_ratings_count         0.000000\n",
      "b_txt_rev_count         0.000000\n",
      "a_id                    0.000000\n",
      "publisher               0.198113\n",
      "b_rating_5_count        0.000000\n",
      "b_rating_4_count        0.000000\n",
      "b_rating_3_count        0.000000\n",
      "b_rating_2_count        0.000000\n",
      "b_rating_1_count        0.000000\n",
      "b_wks_on_list           0.000000\n",
      "a_fans_count            0.000000\n",
      "a_works_count           0.000000\n",
      "gender                  0.000000\n",
      "hometown                0.000000\n",
      "a_avg_rating            0.000000\n",
      "a_ratings_count         0.000000\n",
      "a_text_reviews_count    0.000000\n",
      "author                  0.000000\n",
      "a_wks_on_list           0.000000\n",
      "a_books_on_list         0.000000\n",
      "decade                  0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#drop pub_day, pub_mon because of number of NANs\n",
    "print books.isnull().sum()/len(books)\n",
    "labels = ['pub_day', 'pub_mon']\n",
    "books.drop(labels=labels, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fill publisher NANs with 'Unknown'\n",
    "books['publisher'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#standardize publisher names\n",
    "publishers = {'Berkley': 'Berkley',\n",
    "              'Brown' : 'Little Brown & Co',\n",
    "              'Bantam': 'Bantam',\n",
    "              'Putnam': 'G.P. Putnam\\'s',\n",
    "              'Dell': 'Dell',\n",
    "              'Pocket': 'Pocket',\n",
    "              'Scribner': 'Scribner',\n",
    "              'Doubleday': 'Doubleday',\n",
    "              'Arrow': 'Arrow',\n",
    "              'Atria': 'Atria',\n",
    "              'Vintage': 'Vintage',\n",
    "              'Random': 'Random House',\n",
    "              'Simon': 'Simon & Schuster',\n",
    "              'Signet': 'Signet',\n",
    "              'Martin': 'St. Martin\\'s Press',\n",
    "              'Penguin': 'Penguin',\n",
    "              'Warner': 'Warner',\n",
    "              'NAL': 'NAL',\n",
    "              'Orion': 'Orion',\n",
    "              'Dial': 'Dial',\n",
    "              'Corgi': 'Corgi',\n",
    "              'Harper': 'Harper Collins',\n",
    "              'Collins': 'Harper Collins',\n",
    "              'Ace': 'Ace',\n",
    "              'Knopf': 'Knopf',\n",
    "              'Fawcett': 'Fawcett',\n",
    "              'Tor': 'Tor',\n",
    "              'New English': 'New English',\n",
    "              'Headline': 'Headline',\n",
    "              'Avon': 'Avon',\n",
    "              'Hachette': 'Hachette',\n",
    "              'Viking': 'Viking',\n",
    "              'Morrow': 'Morrow',\n",
    "              'Hodder': 'Hodder & Stoughton',\n",
    "              'Picador': 'Picador',\n",
    "              'Piatkus': 'Piatkus',\n",
    "              'MacMillan': 'MacMillan',\n",
    "              'Houghton': 'Houghton Mifflin',\n",
    "              'B E': 'B E Trice',\n",
    "              'Dodd': 'Dodd Mead'\n",
    "             }\n",
    "\n",
    "for old_pub, new_pub in publishers.items():\n",
    "    books.loc[books['publisher'].str.contains(old_pub), 'publisher'] = new_pub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle cleaned books and authors dataframes to be used in analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books.to_pickle('../data/processed/books_cleaned.pkl')\n",
    "authors.to_pickle('../data/processed/authors_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
