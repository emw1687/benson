{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import operator\n",
    "import copy\n",
    "\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load pickled file into dataframe\n",
    "def open_pickle(pkl_file):\n",
    "    with open(pkl_file, 'rb') as picklefile:\n",
    "        return pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#authors = open_pickle('authors_cleaned.pkl')\n",
    "books = open_pickle('books_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "books.drop(['a_id', 'b_id', 'b_ratings_count'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "books.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing for sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hometown in NY\n",
    "books.loc[books['hometown'].str.contains('New York'), 'a_ny_hometown'] = 1\n",
    "books['a_ny_hometown'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_add_cat_dummies(df, prefix, column):\n",
    "    '''\n",
    "    Make dummy variable columns and merge with existing dataframe\n",
    "    for columns with categorical data\n",
    "    '''\n",
    "    return df.merge(pd.get_dummies(df[column], \n",
    "                                 prefix=prefix, \n",
    "                                 drop_first=True), \n",
    "                  left_index=True, \n",
    "                  right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#decade, gender, publisher\n",
    "#books = make_add_cat_dummies(books, 'b', 'decade')\n",
    "books = make_add_cat_dummies(books, 'a', 'gender')\n",
    "books = make_add_cat_dummies(books, 'a', 'publisher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_add_value_dummies(df, old_column, new_column, value):\n",
    "    '''\n",
    "    Make dummy variable columns\n",
    "    for columns with values above value threshold\n",
    "    '''\n",
    "    df.loc[df[old_column] > value, new_column] = 1\n",
    "    df[new_column].fillna(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#books with more than 1 week on list\n",
    "books = make_add_value_dummies(books, 'b_wks_on_list', 'b_repeat', 1)\n",
    "\n",
    "#authors with more than 1 week on list\n",
    "books = make_add_value_dummies(books, 'a_wks_on_list', 'a_repeat', 1)\n",
    "\n",
    "#authors with more than 1 book on list\n",
    "books = make_add_value_dummies(books, 'a_books_on_list', 'a_b_repeat', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create feature and target dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_target_features(df, target):\n",
    "    '''\n",
    "    df = data frame with all features and target as columns\n",
    "    target = name of column with target (string)\n",
    "    '''\n",
    "    #create target and features dfs\n",
    "    X = copy.deepcopy(df)\n",
    "    y = X.pop(target)\n",
    "    \n",
    "    #only keep numerical features\n",
    "    sklearn_columns = []\n",
    "    for column in X.columns:\n",
    "        if np.dtype(X[column]) == 'float64' or np.dtype(X[column]) == 'int64':\n",
    "            sklearn_columns.append(column)\n",
    "    X = X[sklearn_columns]\n",
    "    \n",
    "    #standardize features\n",
    "    X_scaled = pd.DataFrame(preprocessing.scale(X))\n",
    "    X_scaled.columns = X.columns\n",
    "    \n",
    "    \n",
    "    #return feature and target dfs\n",
    "    return X_scaled, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make and compare models\n",
    "\n",
    "For each model/regularization combination, find the optimal lambda, then create a model using that lambda, calculate the average MSE for that model, and compare MSEs across models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_avg_RMSE(model):\n",
    "    scores = cross_val_score(model, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "    return np.sqrt(-scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_best_model(X_scaled, y):\n",
    "    '''\n",
    "    model_type: LR, Lasso, Ridge, EN\n",
    "    '''\n",
    "    \n",
    "    avg_RMSEs = {}\n",
    "    \n",
    "    #linear\n",
    "    #model_LR = LinearRegression()\n",
    "    \n",
    "    \n",
    "    #lasso\n",
    "    model_LassoCV = LassoCV(cv=5, normalize=False)\n",
    "    model_LassoCV.fit(X_scaled, y)\n",
    "    model_Lasso = Lasso(alpha=model_LassoCV.alpha_)\n",
    "    avg_RMSEs['lasso'] = calc_avg_RMSE(model_Lasso)\n",
    "    \n",
    "    #ridge\n",
    "    model_RidgeCV = RidgeCV(cv=5, normalize=False)\n",
    "    model_RidgeCV.fit(X_scaled, y)\n",
    "    model_Ridge = Ridge(alpha=model_RidgeCV.alpha_)\n",
    "    avg_RMSEs['ridge'] = calc_avg_RMSE(model_Ridge)\n",
    "    \n",
    "    #elasticnet\n",
    "    model_ElasticCV = ElasticNetCV(cv=5, normalize=False)\n",
    "    model_ElasticCV.fit(X_scaled, y)\n",
    "    model_Elastic = ElasticNet(alpha=model_ElasticCV.alpha_)\n",
    "    avg_RMSEs['elasticnet'] = calc_avg_RMSE(model_Elastic)\n",
    "    \n",
    "    models = {'lasso': model_Lasso,\n",
    "             'ridge': model_Ridge,\n",
    "             'elasticnet': model_Elastic}\n",
    "    \n",
    "    best_model_name =  min(avg_RMSEs.iteritems(), key=operator.itemgetter(1))[0]\n",
    "    \n",
    "    print 'best model: ', best_model_name\n",
    "    print 'avg RMSE: ', avg_RMSEs[best_model_name]\n",
    "    #print 'coefficients: ', model_Elastic.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(books.corr());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Model 1: All features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = books['b_avg_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_target_features(books, 'a_avg_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsm = sm.OLS(y,X)\n",
    "fit = lsm.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit.resid.plot(style='o', figsize=(12,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "find_best_model(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Model 2: only books with at least 1 week on NYT list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = books[books['b_repeat']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_target_features(model2, 'b_avg_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "find_best_model(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Model 3: only authors with at least 1 week on NYT list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#only include authors with at least 1 book on NYT list\n",
    "model3 = books[books['a_b_repeat']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_target_features(model3, 'b_avg_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "find_best_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
