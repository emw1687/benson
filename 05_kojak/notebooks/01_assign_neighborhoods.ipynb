{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#pd.options.display.max_rows = 1000\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "import shapefile\n",
    "import csv\n",
    "\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prj(epsg_code):\n",
    "    wkt = urllib.urlopen(\"http://spatialreference.org/ref/epsg/{0}/prettywkt/\".format(epsg_code))\n",
    "    remove_spaces = wkt.read().replace(\" \",\"\")\n",
    "    output = remove_spaces.replace(\"\\n\", \"\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_shp(city):\n",
    "    filepath_in = '../data/external/airbnb/'\n",
    "    filepath_csv = filepath_in + '{}.listings.csv'.format(city)\n",
    "    \n",
    "    filepath_out = '../data/interim/airbnb/'\n",
    "    filepath_shp = filepath_out + 'airbnb_{}.shp'.format(city)\n",
    "    filepath_prj = filepath_out + 'airbnb_{}.prj'.format(city)\n",
    "    \n",
    "    #Create point shapefile writer\n",
    "    w = shapefile.Writer(shapefile.POINT)\n",
    "    \n",
    "    #Add field names to write (id=airbnb listing id)\n",
    "    w.field('id')\n",
    "    \n",
    "    #read in csv and assign pt geometry (aka create shapefile)\n",
    "    with open(filepath_csv) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            #add record for each id\n",
    "            w.record(row['id'])\n",
    "            #create point from coordinates\n",
    "            w.point(float(row['longitude']), float(row['latitude']))\n",
    "    \n",
    "    #save shapefile\n",
    "    w.save(filepath_shp)\n",
    "    \n",
    "    #save prj\n",
    "    with open(filepath_prj, 'w') as f:\n",
    "        #epsg code for WGS84 is 4326\n",
    "        epsg = get_prj('4326')\n",
    "        f.write(epsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_gpd(city, state):\n",
    "    #define filepaths to shapefiles\n",
    "    shp_airbnb = '../data/interim/airbnb/airbnb_{}.shp'.format(city)\n",
    "    zillow = 'ZillowNeighborhoods-{}'.format(state)\n",
    "    shp_neighborhoods = '../data/external/neighborhoods_zillow/{}/{}.shp'.format(zillow, zillow)\n",
    "    \n",
    "    #create gpds\n",
    "    airbnb = gpd.read_file(shp_airbnb)\n",
    "    neighborhoods = gpd.read_file(shp_neighborhoods)\n",
    "    \n",
    "    #project airbnb gpb if needed\n",
    "    if airbnb.crs != neighborhoods.crs:\n",
    "        airbnb_projected = airbnb.to_crs(neighborhoods.crs)\n",
    "    \n",
    "    #return gpds\n",
    "    return airbnb_projected, neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def join_gpds(city, state, airbnb, neighborhoods):\n",
    "    cols = ['Name', 'City', 'State']\n",
    "    neighborhoods = neighborhoods[cols + ['geometry']]\n",
    "    joined = gpd.sjoin(airbnb, neighborhoods, how='left', op='within')\n",
    "    joined['Name'].fillna('OUTSIDE ZILLOW', inplace=True)\n",
    "    joined['State'].fillna(state, inplace=True)\n",
    "    return joined[['id'] + cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities = {'asheville': 'NC',\n",
    "          'austin': 'TX',\n",
    "          'boston': 'MA',\n",
    "          'chicago': 'IL',\n",
    "          'denver': 'CO',\n",
    "          'losangeles': 'CA',\n",
    "          'nashville': 'TN',\n",
    "          'neworleans': 'LA',\n",
    "          'newyorkcity': 'NY',\n",
    "          'oakland': 'CA',\n",
    "          'portland': 'OR',\n",
    "          'sandiego': 'CA',\n",
    "          'sanfrancisco': 'CA',\n",
    "          'santacruz': 'CA',\n",
    "          'seattle': 'WA',\n",
    "          'washingtondc': 'DC',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "losangeles CA 26080\n",
      "sanfrancisco CA 8619\n",
      "newyorkcity NY 40367\n",
      "neworleans LA 4514\n",
      "chicago IL 5147\n",
      "boston MA 3617\n",
      "nashville TN 3277\n",
      "washingtondc DC 3724\n",
      "denver CO 2516\n",
      "santacruz CA failed\n",
      "asheville NC failed\n",
      "sandiego CA 6608\n",
      "portland OR 3504\n",
      "oakland CA 1718\n",
      "austin TX 5835\n",
      "seattle WA 3818\n"
     ]
    }
   ],
   "source": [
    "all_neighborhoods = pd.DataFrame()\n",
    "for city, state in cities.items():\n",
    "    create_shp(city)\n",
    "    airbnb, neighborhoods = create_gpd(city, state)\n",
    "    try:\n",
    "        city_neighborhoods = join_gpds(city, state, airbnb, neighborhoods)\n",
    "        print city, state, len(city_neighborhoods)\n",
    "        all_neighborhoods = all_neighborhoods.append(city_neighborhoods, ignore_index=True)\n",
    "    except:\n",
    "        print city, state, 'failed'\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119344"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_neighborhoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/interim/01_neighborhoods.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(all_neighborhoods, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
