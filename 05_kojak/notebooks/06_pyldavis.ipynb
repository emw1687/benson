{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import operator\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load neighborhood descriptions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "newsgroups = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'))\n",
    "docs_raw = newsgroups.data\n",
    "print(len(docs_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/interim/04_neighborhoods_lemmas.pkl', 'rb') as picklefile:\n",
    "    df_neighborhoods = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_neighborhoods = df_neighborhoods[df_neighborhoods['neighborhood'] != 'OUTSIDE ZILLOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_neighborhoods.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "895"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_neighborhoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_neighborhoods['loc'] = df_neighborhoods['neighborhood'].str.cat(df_neighborhoods['city'], sep=', ').str.cat(df_neighborhoods['state'], sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighborhoods = df_neighborhoods['loc']\n",
    "docs_raw = df_neighborhoods['lemmas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "895"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(895, 500)\n"
     ]
    }
   ],
   "source": [
    "tf_vectorizer = CountVectorizer(#strip_accents = 'unicode',\n",
    "                                #stop_words = 'english',\n",
    "                                #lowercase = True,\n",
    "                                #token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_features = 500,\n",
    "                                ngram_range=(1,2),\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 20)\n",
    "dtm_tf = tf_vectorizer.fit_transform(docs_raw)\n",
    "print(dtm_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Latent Dirichlet Allocation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evaward/anaconda/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
       "             mean_change_tol=0.001, n_jobs=1, n_topics=8, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_tf = LatentDirichletAllocation(n_topics=8, random_state=0)\n",
    "lda_tf.fit(dtm_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the models with pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, pyLDAvis.show() is not the best command\n",
      "      to use. Consider using pyLDAvis.display(), or pyLDAvis.enable_notebook().\n",
      "      See more information at http://pyLDAvis.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8889/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Mar/2017 20:15:37] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Mar/2017 20:15:37] \"GET /LDAvis.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Mar/2017 20:15:37] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Mar/2017 20:15:38] \"GET /LDAvis.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Mar/2017 20:15:38] code 404, message Not Found\n",
      "127.0.0.1 - - [29/Mar/2017 20:15:38] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stopping Server...\n"
     ]
    }
   ],
   "source": [
    "pyLDAvis.show(pyLDAvis.sklearn.prepare(lda_tf, dtm_tf, tf_vectorizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Assign clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_word = lda_tf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_topic = lda_tf.transform(dtm_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics = pd.DataFrame(doc_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_topics['topic'] = df_topics.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics['neighborhood'] = df_neighborhoods['neighborhood']\n",
    "df_topics['city'] = df_neighborhoods['city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics = df_topics[['neighborhood', 'city', 'topic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/interim/06_topics.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(df_topics, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#csv for d3 visualization of stemplots\n",
    "df_lda_topic_word = pd.DataFrame(topic_word).T\n",
    "\n",
    "vocab = tf_vectorizer.vocabulary_\n",
    "sorted_lda_words = sorted(vocab.items(), key=operator.itemgetter(1))\n",
    "indices = [x[0].encode('utf-8') for x in sorted_lda_words]\n",
    "\n",
    "df_lda_topic_word['word'] = indices\n",
    "\n",
    "#topic_word importances\n",
    "df_lda_topic_word.to_csv('../reports/viz/data/lda_topic_word.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
